{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNkPCL04kd+XDsXBQXWBNkk"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b17e423d692643ca89744996b6556a52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a0f12d3b0cbe450b923f6107a930bf36",
              "IPY_MODEL_249994e0902f4cb4b58eeb5d949d852d",
              "IPY_MODEL_e8488d075e3f412c8bdd487dc650cb2d"
            ],
            "layout": "IPY_MODEL_b2c9139dec134e19927f2bb44b3aafc6"
          }
        },
        "a0f12d3b0cbe450b923f6107a930bf36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e55343677b084d7db1dde13139e174f3",
            "placeholder": "​",
            "style": "IPY_MODEL_d4c00d4d9951424098de39d6f3f70c50",
            "value": "100%"
          }
        },
        "249994e0902f4cb4b58eeb5d949d852d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd74a84d74fd44be824c607790711f21",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a6bd709355f44895bb5049e69af37445",
            "value": 2
          }
        },
        "e8488d075e3f412c8bdd487dc650cb2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f84ee909e17412a83c6f654fde2edf7",
            "placeholder": "​",
            "style": "IPY_MODEL_7b896a46abcf42f1b5b78ca2ff02deae",
            "value": " 2/2 [00:00&lt;00:00, 28.63it/s]"
          }
        },
        "b2c9139dec134e19927f2bb44b3aafc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e55343677b084d7db1dde13139e174f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4c00d4d9951424098de39d6f3f70c50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd74a84d74fd44be824c607790711f21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6bd709355f44895bb5049e69af37445": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8f84ee909e17412a83c6f654fde2edf7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b896a46abcf42f1b5b78ca2ff02deae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "OygNAcZsejcP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c40bf7e6-24c3-41f1-bf80-1e529bf07475"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.29.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "raw_datasets = load_dataset(\"squad\")\n",
        "raw_datasets"
      ],
      "metadata": {
        "id": "08BbUw6kzCM1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260,
          "referenced_widgets": [
            "b17e423d692643ca89744996b6556a52",
            "a0f12d3b0cbe450b923f6107a930bf36",
            "249994e0902f4cb4b58eeb5d949d852d",
            "e8488d075e3f412c8bdd487dc650cb2d",
            "b2c9139dec134e19927f2bb44b3aafc6",
            "e55343677b084d7db1dde13139e174f3",
            "d4c00d4d9951424098de39d6f3f70c50",
            "cd74a84d74fd44be824c607790711f21",
            "a6bd709355f44895bb5049e69af37445",
            "8f84ee909e17412a83c6f654fde2edf7",
            "7b896a46abcf42f1b5b78ca2ff02deae"
          ]
        },
        "outputId": "f8cc0a4d-adf8-4a67-fefd-27f3a681409b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset squad (/root/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b17e423d692643ca89744996b6556a52"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
              "        num_rows: 87599\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
              "        num_rows: 10570\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_datasets[\"train\"][1][\"title\"]"
      ],
      "metadata": {
        "id": "O76m4uTezNwe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "83800e31-6621-4496-c88e-3ca33bcfc158"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'University_of_Notre_Dame'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_datasets[\"train\"][1][\"context\"]"
      ],
      "metadata": {
        "id": "0kSsk7bXzUYT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "outputId": "2fb0868f-6e88-4ee0-aee4-47b028380d11"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_datasets[\"train\"][1][\"question\"]"
      ],
      "metadata": {
        "id": "_EgizFoozYrc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "db7334ca-67e0-49a2-f8eb-79e866e5a88b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'What is in front of the Notre Dame Main Building?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_datasets[\"train\"][1][\"answers\"]"
      ],
      "metadata": {
        "id": "MDzo2KkYzY1X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f31bfff-a500-4447-ddac-8218daf9b21e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': ['a copper statue of Christ'], 'answer_start': [188]}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for train set, ensure that there'e always 1 answer\n",
        "# not multiple answers, or no answers\n",
        "raw_datasets[\"train\"].filter(lambda x: len(x[\"answers\"][\"text\"]) != 1)"
      ],
      "metadata": {
        "id": "J-u7CKnoz49C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4facd39-ebab-4783-8bba-ff0d6dba89d4"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453/cache-7127000c44dfd643.arrow\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
              "    num_rows: 0\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for validation set, there may be multiple answers\n",
        "raw_datasets[\"validation\"][2][\"answers\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTYAU3_fEjqL",
        "outputId": "97365f71-4967-43a6-8f93-35c32d90dfa2"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': ['Santa Clara, California',\n",
              "  \"Levi's Stadium\",\n",
              "  \"Levi's Stadium in the San Francisco Bay Area at Santa Clara, California.\"],\n",
              " 'answer_start': [403, 355, 355]}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# why are there multiple answers?\n",
        "raw_datasets[\"validation\"][2][\"context\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "y7D7mjbbEu6z",
        "outputId": "4f804400-940b-4a2c-9ec5-48a1a4b4e757"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi\\'s Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_datasets[\"validation\"][2][\"question\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "j_K7QEvhGUBQ",
        "outputId": "93dc6fc5-040d-4359-8eb6-8e3224447405"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Where did Super Bowl 50 take place?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# they may even be the same!\n",
        "raw_datasets[\"validation\"][0][\"answers\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2vScoQ2GZ9Z",
        "outputId": "71e4a88f-5e16-4d2d-c810-addef062a683"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': ['Denver Broncos', 'Denver Broncos', 'Denver Broncos'],\n",
              " 'answer_start': [177, 177, 177]}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_checkpoint = \"distilbert-base-cased\"\n",
        "# model_checkpoint = \"bert-base-cased\" # try it out\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ],
      "metadata": {
        "id": "FWVNH407HDc0"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test the tokenizer on a context-question pair\n",
        "context = raw_datasets[\"train\"][1][\"context\"]\n",
        "question = raw_datasets[\"train\"][1][\"question\"]\n",
        "\n",
        "inputs = tokenizer(question, context)\n",
        "tokenizer.decode(inputs[\"input_ids\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "RU4haPlcHkFH",
        "outputId": "8ad26d62-155c-4795-eda0-fd34cb994661"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[CLS] What is in front of the Notre Dame Main Building? [SEP] Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \" Venite Ad Me Omnes \". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive ( and in a direct line that connects through 3 statues and the Gold Dome ), is a simple, modern stone statue of Mary. [SEP]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# what if the context is really long?\n",
        "# split it into multiple samples\n",
        "inut = tokenizer(\n",
        "    question,\n",
        "    context,\n",
        "    max_length=100,\n",
        "    truncation=\"only_second\", # truncates the context, not the question\n",
        "    stride=50, # to not cut off the question\n",
        "    return_overflowing_tokens=True,\n",
        ")\n",
        "\n",
        "for ids in inputs[\"input_ids\"]:\n",
        "  print(tokenizer.decode(ids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaEgQp7yK1kw",
        "outputId": "3914d7d3-58d0-4b3d-824c-8c0279536cc7"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS]\n",
            "What\n",
            "is\n",
            "in\n",
            "front\n",
            "of\n",
            "the\n",
            "Notre\n",
            "Dame\n",
            "Main\n",
            "Building\n",
            "?\n",
            "[SEP]\n",
            "Architectural\n",
            "##ly\n",
            ",\n",
            "the\n",
            "school\n",
            "has\n",
            "a\n",
            "Catholic\n",
            "character\n",
            ".\n",
            "At\n",
            "##op\n",
            "the\n",
            "Main\n",
            "Building\n",
            "'\n",
            "s\n",
            "gold\n",
            "dome\n",
            "is\n",
            "a\n",
            "golden\n",
            "statue\n",
            "of\n",
            "the\n",
            "Virgin\n",
            "Mary\n",
            ".\n",
            "Immediately\n",
            "in\n",
            "front\n",
            "of\n",
            "the\n",
            "Main\n",
            "Building\n",
            "and\n",
            "facing\n",
            "it\n",
            ",\n",
            "is\n",
            "a\n",
            "copper\n",
            "statue\n",
            "of\n",
            "Christ\n",
            "with\n",
            "arms\n",
            "up\n",
            "##rai\n",
            "##sed\n",
            "with\n",
            "the\n",
            "legend\n",
            "\"\n",
            "V\n",
            "##eni\n",
            "##te\n",
            "Ad\n",
            "Me\n",
            "O\n",
            "##m\n",
            "##nes\n",
            "\"\n",
            ".\n",
            "Next\n",
            "to\n",
            "the\n",
            "Main\n",
            "Building\n",
            "is\n",
            "the\n",
            "Basilica\n",
            "of\n",
            "the\n",
            "Sacred\n",
            "Heart\n",
            ".\n",
            "Immediately\n",
            "behind\n",
            "the\n",
            "b\n",
            "##asi\n",
            "##lica\n",
            "is\n",
            "the\n",
            "G\n",
            "##rot\n",
            "##to\n",
            ",\n",
            "a\n",
            "Marian\n",
            "place\n",
            "of\n",
            "prayer\n",
            "and\n",
            "reflection\n",
            ".\n",
            "It\n",
            "is\n",
            "a\n",
            "replica\n",
            "of\n",
            "the\n",
            "g\n",
            "##rot\n",
            "##to\n",
            "at\n",
            "Lou\n",
            "##rdes\n",
            ",\n",
            "France\n",
            "where\n",
            "the\n",
            "Virgin\n",
            "Mary\n",
            "reputed\n",
            "##ly\n",
            "appeared\n",
            "to\n",
            "Saint\n",
            "Bern\n",
            "##ade\n",
            "##tte\n",
            "So\n",
            "##ubi\n",
            "##rous\n",
            "in\n",
            "1858\n",
            ".\n",
            "At\n",
            "the\n",
            "end\n",
            "of\n",
            "the\n",
            "main\n",
            "drive\n",
            "(\n",
            "and\n",
            "in\n",
            "a\n",
            "direct\n",
            "line\n",
            "that\n",
            "connects\n",
            "through\n",
            "3\n",
            "statues\n",
            "and\n",
            "the\n",
            "Gold\n",
            "Dome\n",
            ")\n",
            ",\n",
            "is\n",
            "a\n",
            "simple\n",
            ",\n",
            "modern\n",
            "stone\n",
            "statue\n",
            "of\n",
            "Mary\n",
            ".\n",
            "[SEP]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check the keys of the result\n",
        "inputs.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Kzv72uXL3tU",
        "outputId": "8f7f2ef0-ebdb-4973-eb50-1ecfe45c3444"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# wha's the new key?\n",
        "inputs['attention_mask']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nBJ5A7fMbdo",
        "outputId": "fb3b8aac-3b4e-44f2-c5a1-e0d0246db1b6"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# \n",
        "inputs = tokenizer(\n",
        "    raw_datasets[\"train\"][:3][\"question\"],\n",
        "    raw_datasets[\"train\"][:3][\"context\"],\n",
        "    max_length=100,\n",
        "    truncation=\"only_second\",\n",
        "    stride=50,\n",
        "    return_overflowing_tokens=True,\n",
        "    return_offsets_mapping=True,\n",
        ")"
      ],
      "metadata": {
        "id": "Wi6xYRT0MkxD"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5:38\n",
        "inputs = tokenizer(\n",
        "    question,\n",
        "    context,\n",
        "    max_length=100,\n",
        "    truncation=\"only_second\",\n",
        "    stride=50,\n",
        "    return_overflowing_tokens=True,\n",
        "    return_offsets_mapping=True,\n",
        ")\n",
        "inputs.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0u6_Mg2Nh9v",
        "outputId": "4027d75b-1fa8-4840-f4fb-c4615523f3e9"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask', 'offset_mapping', 'overflow_to_sample_mapping'])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# what is this offset_mapping?\n",
        "# it tells us the location of each token\n",
        "# notes:\n",
        "# special tokens take up 0 space (0, 0)\n",
        "# the question portion is the same for each sample \"what is in\" = (what start at 0, 4 char long etc..)\n",
        "# the context portion starting point increases in each sample\n",
        "inputs[\"offset_mapping\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmz7R6GwPlA6",
        "outputId": "addd60cb-d55c-463d-e200-dd2a68cb3caf"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[(0, 0),\n",
              "  (0, 4),\n",
              "  (5, 7),\n",
              "  (8, 10),\n",
              "  (11, 16),\n",
              "  (17, 19),\n",
              "  (20, 23),\n",
              "  (24, 29),\n",
              "  (30, 34),\n",
              "  (35, 39),\n",
              "  (40, 48),\n",
              "  (48, 49),\n",
              "  (0, 0),\n",
              "  (0, 13),\n",
              "  (13, 15),\n",
              "  (15, 16),\n",
              "  (17, 20),\n",
              "  (21, 27),\n",
              "  (28, 31),\n",
              "  (32, 33),\n",
              "  (34, 42),\n",
              "  (43, 52),\n",
              "  (52, 53),\n",
              "  (54, 56),\n",
              "  (56, 58),\n",
              "  (59, 62),\n",
              "  (63, 67),\n",
              "  (68, 76),\n",
              "  (76, 77),\n",
              "  (77, 78),\n",
              "  (79, 83),\n",
              "  (84, 88),\n",
              "  (89, 91),\n",
              "  (92, 93),\n",
              "  (94, 100),\n",
              "  (101, 107),\n",
              "  (108, 110),\n",
              "  (111, 114),\n",
              "  (115, 121),\n",
              "  (122, 126),\n",
              "  (126, 127),\n",
              "  (128, 139),\n",
              "  (140, 142),\n",
              "  (143, 148),\n",
              "  (149, 151),\n",
              "  (152, 155),\n",
              "  (156, 160),\n",
              "  (161, 169),\n",
              "  (170, 173),\n",
              "  (174, 180),\n",
              "  (181, 183),\n",
              "  (183, 184),\n",
              "  (185, 187),\n",
              "  (188, 189),\n",
              "  (190, 196),\n",
              "  (197, 203),\n",
              "  (204, 206),\n",
              "  (207, 213),\n",
              "  (214, 218),\n",
              "  (219, 223),\n",
              "  (224, 226),\n",
              "  (226, 229),\n",
              "  (229, 232),\n",
              "  (233, 237),\n",
              "  (238, 241),\n",
              "  (242, 248),\n",
              "  (249, 250),\n",
              "  (250, 251),\n",
              "  (251, 254),\n",
              "  (254, 256),\n",
              "  (257, 259),\n",
              "  (260, 262),\n",
              "  (263, 264),\n",
              "  (264, 265),\n",
              "  (265, 268),\n",
              "  (268, 269),\n",
              "  (269, 270),\n",
              "  (271, 275),\n",
              "  (276, 278),\n",
              "  (279, 282),\n",
              "  (283, 287),\n",
              "  (288, 296),\n",
              "  (297, 299),\n",
              "  (300, 303),\n",
              "  (304, 312),\n",
              "  (313, 315),\n",
              "  (316, 319),\n",
              "  (320, 326),\n",
              "  (327, 332),\n",
              "  (332, 333),\n",
              "  (334, 345),\n",
              "  (346, 352),\n",
              "  (353, 356),\n",
              "  (357, 358),\n",
              "  (358, 361),\n",
              "  (361, 365),\n",
              "  (366, 368),\n",
              "  (369, 372),\n",
              "  (373, 374),\n",
              "  (0, 0)],\n",
              " [(0, 0),\n",
              "  (0, 4),\n",
              "  (5, 7),\n",
              "  (8, 10),\n",
              "  (11, 16),\n",
              "  (17, 19),\n",
              "  (20, 23),\n",
              "  (24, 29),\n",
              "  (30, 34),\n",
              "  (35, 39),\n",
              "  (40, 48),\n",
              "  (48, 49),\n",
              "  (0, 0),\n",
              "  (174, 180),\n",
              "  (181, 183),\n",
              "  (183, 184),\n",
              "  (185, 187),\n",
              "  (188, 189),\n",
              "  (190, 196),\n",
              "  (197, 203),\n",
              "  (204, 206),\n",
              "  (207, 213),\n",
              "  (214, 218),\n",
              "  (219, 223),\n",
              "  (224, 226),\n",
              "  (226, 229),\n",
              "  (229, 232),\n",
              "  (233, 237),\n",
              "  (238, 241),\n",
              "  (242, 248),\n",
              "  (249, 250),\n",
              "  (250, 251),\n",
              "  (251, 254),\n",
              "  (254, 256),\n",
              "  (257, 259),\n",
              "  (260, 262),\n",
              "  (263, 264),\n",
              "  (264, 265),\n",
              "  (265, 268),\n",
              "  (268, 269),\n",
              "  (269, 270),\n",
              "  (271, 275),\n",
              "  (276, 278),\n",
              "  (279, 282),\n",
              "  (283, 287),\n",
              "  (288, 296),\n",
              "  (297, 299),\n",
              "  (300, 303),\n",
              "  (304, 312),\n",
              "  (313, 315),\n",
              "  (316, 319),\n",
              "  (320, 326),\n",
              "  (327, 332),\n",
              "  (332, 333),\n",
              "  (334, 345),\n",
              "  (346, 352),\n",
              "  (353, 356),\n",
              "  (357, 358),\n",
              "  (358, 361),\n",
              "  (361, 365),\n",
              "  (366, 368),\n",
              "  (369, 372),\n",
              "  (373, 374),\n",
              "  (374, 377),\n",
              "  (377, 379),\n",
              "  (379, 380),\n",
              "  (381, 382),\n",
              "  (383, 389),\n",
              "  (390, 395),\n",
              "  (396, 398),\n",
              "  (399, 405),\n",
              "  (406, 409),\n",
              "  (410, 420),\n",
              "  (420, 421),\n",
              "  (422, 424),\n",
              "  (425, 427),\n",
              "  (428, 429),\n",
              "  (430, 437),\n",
              "  (438, 440),\n",
              "  (441, 444),\n",
              "  (445, 446),\n",
              "  (446, 449),\n",
              "  (449, 451),\n",
              "  (452, 454),\n",
              "  (455, 458),\n",
              "  (458, 462),\n",
              "  (462, 463),\n",
              "  (464, 470),\n",
              "  (471, 476),\n",
              "  (477, 480),\n",
              "  (481, 487),\n",
              "  (488, 492),\n",
              "  (493, 500),\n",
              "  (500, 502),\n",
              "  (503, 511),\n",
              "  (512, 514),\n",
              "  (515, 520),\n",
              "  (521, 525),\n",
              "  (525, 528),\n",
              "  (0, 0)],\n",
              " [(0, 0),\n",
              "  (0, 4),\n",
              "  (5, 7),\n",
              "  (8, 10),\n",
              "  (11, 16),\n",
              "  (17, 19),\n",
              "  (20, 23),\n",
              "  (24, 29),\n",
              "  (30, 34),\n",
              "  (35, 39),\n",
              "  (40, 48),\n",
              "  (48, 49),\n",
              "  (0, 0),\n",
              "  (313, 315),\n",
              "  (316, 319),\n",
              "  (320, 326),\n",
              "  (327, 332),\n",
              "  (332, 333),\n",
              "  (334, 345),\n",
              "  (346, 352),\n",
              "  (353, 356),\n",
              "  (357, 358),\n",
              "  (358, 361),\n",
              "  (361, 365),\n",
              "  (366, 368),\n",
              "  (369, 372),\n",
              "  (373, 374),\n",
              "  (374, 377),\n",
              "  (377, 379),\n",
              "  (379, 380),\n",
              "  (381, 382),\n",
              "  (383, 389),\n",
              "  (390, 395),\n",
              "  (396, 398),\n",
              "  (399, 405),\n",
              "  (406, 409),\n",
              "  (410, 420),\n",
              "  (420, 421),\n",
              "  (422, 424),\n",
              "  (425, 427),\n",
              "  (428, 429),\n",
              "  (430, 437),\n",
              "  (438, 440),\n",
              "  (441, 444),\n",
              "  (445, 446),\n",
              "  (446, 449),\n",
              "  (449, 451),\n",
              "  (452, 454),\n",
              "  (455, 458),\n",
              "  (458, 462),\n",
              "  (462, 463),\n",
              "  (464, 470),\n",
              "  (471, 476),\n",
              "  (477, 480),\n",
              "  (481, 487),\n",
              "  (488, 492),\n",
              "  (493, 500),\n",
              "  (500, 502),\n",
              "  (503, 511),\n",
              "  (512, 514),\n",
              "  (515, 520),\n",
              "  (521, 525),\n",
              "  (525, 528),\n",
              "  (528, 531),\n",
              "  (532, 534),\n",
              "  (534, 537),\n",
              "  (537, 541),\n",
              "  (542, 544),\n",
              "  (545, 549),\n",
              "  (549, 550),\n",
              "  (551, 553),\n",
              "  (554, 557),\n",
              "  (558, 561),\n",
              "  (562, 564),\n",
              "  (565, 568),\n",
              "  (569, 573),\n",
              "  (574, 579),\n",
              "  (580, 581),\n",
              "  (581, 584),\n",
              "  (585, 587),\n",
              "  (588, 589),\n",
              "  (590, 596),\n",
              "  (597, 601),\n",
              "  (602, 606),\n",
              "  (607, 615),\n",
              "  (616, 623),\n",
              "  (624, 625),\n",
              "  (626, 633),\n",
              "  (634, 637),\n",
              "  (638, 641),\n",
              "  (642, 646),\n",
              "  (647, 651),\n",
              "  (651, 652),\n",
              "  (652, 653),\n",
              "  (654, 656),\n",
              "  (657, 658),\n",
              "  (659, 665),\n",
              "  (665, 666),\n",
              "  (667, 673),\n",
              "  (0, 0)],\n",
              " [(0, 0),\n",
              "  (0, 4),\n",
              "  (5, 7),\n",
              "  (8, 10),\n",
              "  (11, 16),\n",
              "  (17, 19),\n",
              "  (20, 23),\n",
              "  (24, 29),\n",
              "  (30, 34),\n",
              "  (35, 39),\n",
              "  (40, 48),\n",
              "  (48, 49),\n",
              "  (0, 0),\n",
              "  (458, 462),\n",
              "  (462, 463),\n",
              "  (464, 470),\n",
              "  (471, 476),\n",
              "  (477, 480),\n",
              "  (481, 487),\n",
              "  (488, 492),\n",
              "  (493, 500),\n",
              "  (500, 502),\n",
              "  (503, 511),\n",
              "  (512, 514),\n",
              "  (515, 520),\n",
              "  (521, 525),\n",
              "  (525, 528),\n",
              "  (528, 531),\n",
              "  (532, 534),\n",
              "  (534, 537),\n",
              "  (537, 541),\n",
              "  (542, 544),\n",
              "  (545, 549),\n",
              "  (549, 550),\n",
              "  (551, 553),\n",
              "  (554, 557),\n",
              "  (558, 561),\n",
              "  (562, 564),\n",
              "  (565, 568),\n",
              "  (569, 573),\n",
              "  (574, 579),\n",
              "  (580, 581),\n",
              "  (581, 584),\n",
              "  (585, 587),\n",
              "  (588, 589),\n",
              "  (590, 596),\n",
              "  (597, 601),\n",
              "  (602, 606),\n",
              "  (607, 615),\n",
              "  (616, 623),\n",
              "  (624, 625),\n",
              "  (626, 633),\n",
              "  (634, 637),\n",
              "  (638, 641),\n",
              "  (642, 646),\n",
              "  (647, 651),\n",
              "  (651, 652),\n",
              "  (652, 653),\n",
              "  (654, 656),\n",
              "  (657, 658),\n",
              "  (659, 665),\n",
              "  (665, 666),\n",
              "  (667, 673),\n",
              "  (674, 679),\n",
              "  (680, 686),\n",
              "  (687, 689),\n",
              "  (690, 694),\n",
              "  (694, 695),\n",
              "  (0, 0)]]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check size of list\n",
        "len(inputs['offset_mapping'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWUsTEDQsrYh",
        "outputId": "047b2730-e884-4cee-90a7-1f2cde220b26"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check the len of the elements inside the list\n",
        "len(inputs['offset_mapping'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Twfr3vmt7uW",
        "outputId": "2ec8cddf-0b18-4cc5-a287-34db5158ca14"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# \n",
        "print(inputs.sequence_ids(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbV3IP1pt_C3",
        "outputId": "2f5effb5-6e71-4522-c526-2c7021b54d18"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[None, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, None, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, None]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# problem: the position of the answer will change in each\n",
        "# window of the context\n",
        "# the answer is also the target for the neural network\n",
        "# how can we recompute the targets for each context window?\n",
        "\n",
        "# snce we took the question and context from this sample earlier\n",
        "answer = raw_datasets[\"train\"][1][\"answers\"]\n",
        "answer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3DgcZJWuEIu",
        "outputId": "bc1cbe8f-dcd8-4e1b-97c5-d3d5cac888f4"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': ['a copper statue of Christ'], 'answer_start': [188]}"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check the type\n",
        "type(inputs.sequence_ids(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkALK7Lh8JvQ",
        "outputId": "235d9082-aef6-423a-8a29-4bc09fbd9373"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# find the start and end of the context (the first and last '1')\n",
        "sequence_ids = inputs.sequence_ids(0)\n",
        "\n",
        "ctx_start = sequence_ids.index(1) # first occurence\n",
        "ctx_end = len(sequence_ids) - sequence_ids[::-1].index(1) -1 # last occurence\n",
        "\n",
        "ctx_start, ctx_end"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jxYRWUdByO0",
        "outputId": "724fb00d-92b3-4680-f2f7-948f31712b24"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13, 98)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check whether or not the answer is fully contained within the context\n",
        "# if not, target is (start, end) = (0, 0)\n",
        "\n",
        "ans_start_char = answer['answer_start'][0]\n",
        "ans_end_char = ans_start_char + len(answer['text'][0])\n",
        "\n",
        "offset = inputs['offset_mapping'][0]\n",
        "\n",
        "start_idx = 0\n",
        "end_idx = 0\n",
        "\n",
        "if offset[ctx_start][0] > ans_start_char or offset[ctx_end][1] < ans_end_char:\n",
        "  print(\"target is (0, 0)\")\n",
        "  # nothing else to do\n",
        "else:\n",
        "  # find the start and end TOKEN positions\n",
        "  # the trick is knowing what is in units of tokens and what is in units of charachters\n",
        "\n",
        "  # recall: the offset_mapping contains the charachter positions of each token\n",
        "\n",
        "  i = ctx_start\n",
        "  for start_end_char in offset[ctx_start:]:\n",
        "    start, end = start_end_char\n",
        "    if start == ans_start_char:\n",
        "      start_idx = i\n",
        "      # don't break yet\n",
        "\n",
        "    if end == ans_end_char:\n",
        "      end_idx = i\n",
        "      break\n",
        "\n",
        "    i += 1\n",
        "\n",
        "start_idx, end_idx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvVRJDqiCZkW",
        "outputId": "041a4d8b-d46d-4116-c864-8e162710b08f"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(53, 57)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check\n",
        "input_ids = inputs['input_ids'][0]\n",
        "input_ids[start_idx : end_idx + 1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlnT19DOFbwX",
        "outputId": "41ac4869-f645-482f-ad34-6b414249403c"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[170, 7335, 5921, 1104, 4028]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert the numbers above into text\n",
        "tokenizer.decode(input_ids[start_idx : end_idx + 1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WDJ_w9AgGULw",
        "outputId": "ee59eb41-33d0-4960-c0fa-c756c8155e1d"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'a copper statue of Christ'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_answer_token_idx(\n",
        "    ctx_start,\n",
        "    ctx_end,\n",
        "    ans_start_char,\n",
        "    ans_end_char,\n",
        "    offset):\n",
        "\n",
        "  start_idx = 0\n",
        "  end_idx = 0\n",
        "\n",
        "  if offset[ctx_start][0] > ans_start_char or offset[ctx_end][1] < ans_end_char:\n",
        "    pass\n",
        "    # nothing else to do\n",
        "  else:\n",
        "    # find the start and end TOKEN positions\n",
        "    # the trick is knowing what is in units of tokens and what is in units of charachters\n",
        "\n",
        "    # recall: the offset_mapping contains the charachter positions of each token\n",
        "    i = ctx_start\n",
        "    for start_end_char in offset[ctx_start:]:\n",
        "      start, end = start_end_char\n",
        "      if start == ans_start_char:\n",
        "        start_idx = i\n",
        "      # don't break yet\n",
        "\n",
        "      if end == ans_end_char:\n",
        "        end_idx = i\n",
        "        break\n",
        "\n",
        "      i += 1\n",
        "\n",
        "  return start_idx, end_idx"
      ],
      "metadata": {
        "id": "xhcUcedMGdNC"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# try it on all context windows\n",
        "# sometimes, the answer won't apear!\n",
        "\n",
        "start_idxs = []\n",
        "end_idxs = []\n",
        "\n",
        "for i, offset in enumerate(inputs['offset_mapping']):\n",
        "  # the final window may not be full size - cant't assume 100\n",
        "  sequence_ids = inputs.sequence_ids(i)\n",
        "\n",
        "  # find start + end of context (first 1 and last 1)\n",
        "  ctx_start = sequence_ids.index(1)\n",
        "  ctx_end = len(sequence_ids) - sequence_ids[::-1].index(1) -1\n",
        "\n",
        "  start_idx, end_idx = find_answer_token_idx(\n",
        "      ctx_start,\n",
        "      ctx_end,\n",
        "      ans_start_char,\n",
        "      ans_end_char,\n",
        "      offset\n",
        "  )\n",
        "\n",
        "  start_idxs.append(start_idx)\n",
        "  end_idxs.append(end_idx)\n",
        "\n",
        "start_idxs, end_idxs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Mox4bieImVG",
        "outputId": "a61e4a7e-be5e-40ec-8c4f-3802d9d07b61"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([53, 17, 0, 0], [57, 21, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# some questions have leading and/or trailing whitespace\n",
        "for q in raw_datasets[\"train\"][\"queston\"][:1000]:\n",
        "  if q.strip() != q:\n",
        "    print(q)"
      ],
      "metadata": {
        "id": "ypVX9Z9Jh7hI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S_7Cjd3BiTDz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}